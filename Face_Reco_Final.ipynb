{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face Reco Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bzo7-UhDB2f"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn_-jTLuDwpk"
      },
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(\"/content/data_1 (2).zip\", 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTNTaRfNDy0Y"
      },
      "source": [
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "dirs = \"data/train/\"\n",
        "img_size = 60\n",
        "\n",
        "data = []\n",
        "for name in os.listdir(dirs):\n",
        "    for f in os.listdir(dirs+name):\n",
        "        f = cv2.imread(os.path.join(dirs+name, f))\n",
        "        faces = face_cascade.detectMultiScale(f,1.3,5)\n",
        "        for x,y,w,h in faces:\n",
        "            img = f[y:y+h, x:x+w]\n",
        "            img = cv2.resize(img, (img_size,img_size))\n",
        "            data.append((img, name))\n",
        "            \n",
        "df = pd.DataFrame(data, columns=[\"image\", \"name\"])\n",
        "print(\"Length:\",len(df))\n",
        "#df.head"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DgiCAZDDnKF"
      },
      "source": [
        "dirs = \"data/val/\"\n",
        "\n",
        "data = []\n",
        "for name in os.listdir(dirs):\n",
        "    for f in os.listdir(dirs+name):\n",
        "        f = cv2.imread(os.path.join(dirs+name, f))\n",
        "        faces = face_cascade.detectMultiScale(f,1.3,5)\n",
        "        for x,y,w,h in faces:\n",
        "            img = f[y:y+h, x:x+w]\n",
        "            img = cv2.resize(img, (img_size,img_size))\n",
        "            data.append((img, name))\n",
        "            \n",
        "df_test = pd.DataFrame(data, columns=[\"image\", \"name\"])\n",
        "print(\"Test size: \", len(df_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xMpb6vtE8A7"
      },
      "source": [
        "le = LabelEncoder()\n",
        "le.fit(df[\"name\"].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8lNtGkvE81s"
      },
      "source": [
        "x_train = list(df.image.values)\n",
        "x_train = np.array(x_train)\n",
        "x_train = x_train/255\n",
        "print(x_train.shape)\n",
        "\n",
        "y_train = le.transform(df[\"name\"].values)\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NotnsKdbE89f"
      },
      "source": [
        "x_test = list(df_test.image.values)\n",
        "x_test = np.array(x_test)\n",
        "x_test = x_test/255\n",
        "print(x_test.shape)\n",
        "\n",
        "y_test = le.transform(df_test[\"name\"].values)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAabQ4bxE9AX"
      },
      "source": [
        "people_num = len(np.unique(y_train))\n",
        "people_num"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlRJaKt1E9C0"
      },
      "source": [
        "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
        "    total_lenght = y_pred.shape.as_list()[-1]\n",
        "    anchor, positive, negative = y_pred[:,:int(1/3*total_lenght)], y_pred[:,int(1/3*total_lenght):int(2/3*total_lenght)], y_pred[:,int(2/3*total_lenght):]\n",
        "    \n",
        "    pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=-1)\n",
        "    neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=-1)\n",
        "    basic_loss = pos_dist - neg_dist + alpha\n",
        "    loss = tf.reduce_sum(tf.maximum(basic_loss,0.0))\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQuryY1UE9Fe"
      },
      "source": [
        "def generate_triplets(x, y, num_same = 4, num_diff = 4):\n",
        "    anchor_images = np.array([]).reshape((-1,)+ x.shape[1:])\n",
        "    same_images = np.array([]).reshape((-1,)+ x.shape[1:])\n",
        "    diff_images = np.array([]).reshape((-1,)+ x.shape[1:])\n",
        "    \n",
        "    for i in range(len(y)):\n",
        "        point = y[i]        \n",
        "        anchor = x[i]\n",
        "        \n",
        "        same_pairs = np.where(y == point)[0]\n",
        "        same_pairs = np.delete(same_pairs , np.where(same_pairs == i))\n",
        "        diff_pairs = np.where(y != point)[0]\n",
        "               \n",
        "        same = x[np.random.choice(same_pairs,num_same)]\n",
        "        diff = x[np.random.choice(diff_pairs,num_diff)]\n",
        "        \n",
        "        anchor_images = np.concatenate((anchor_images, np.tile(anchor, (num_same * num_diff, 1, 1, 1) )), axis = 0)\n",
        "                                       \n",
        "        for s in same:\n",
        "            same_images = np.concatenate((same_images, np.tile(s, (num_same, 1, 1, 1) )), axis = 0)\n",
        "            \n",
        "        diff_images = np.concatenate((diff_images, np.tile(diff, (num_diff, 1, 1, 1) )), axis = 0)\n",
        "        \n",
        "    return anchor_images, same_images, diff_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekmprApAE9Ia"
      },
      "source": [
        "anchor_images, same_images, diff_images = generate_triplets(x_train,y_train, num_same= 10, num_diff=10)\n",
        "print(anchor_images.shape, same_images.shape, diff_images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OWsdNFoE9L8"
      },
      "source": [
        "idx = 90\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(anchor_images[idx])\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(same_images[idx])\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(diff_images[idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfkBGQ2rFpuG"
      },
      "source": [
        "def get_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(64, kernel_size=3, strides=2, padding='same', input_shape=(img_size,img_size,3), activation='relu'))\n",
        "    model.add(tf.keras.layers.Conv2D(128, kernel_size=3, strides=2, padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.Conv2D(64, kernel_size=3, strides=2, padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.Conv2D(64, kernel_size=1, strides=2, padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.1))\n",
        "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Dense(128))\n",
        "              \n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Dxj68ztGQb1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIoevLZ-Fttx"
      },
      "source": [
        "\n",
        "anchor_input = tf.keras.layers.Input((img_size, img_size, 3), name='anchor_input')\n",
        "positive_input = tf.keras.layers.Input((img_size, img_size, 3), name='positive_input')\n",
        "negative_input = tf.keras.layers.Input((img_size, img_size, 3), name='negative_input')\n",
        "\n",
        "shared_dnn = get_model()\n",
        "\n",
        "encoded_anchor = shared_dnn(anchor_input)\n",
        "encoded_positive = shared_dnn(positive_input)\n",
        "encoded_negative = shared_dnn(negative_input)\n",
        "\n",
        "merged_vector = tf.keras.layers.concatenate([encoded_anchor, encoded_positive, encoded_negative],\n",
        "                                            axis=-1, name='merged_layer')\n",
        "\n",
        "model = tf.keras.Model(inputs=[anchor_input,positive_input, negative_input], outputs=merged_vector)\n",
        "model.summary()\n",
        "model.compile(loss=triplet_loss, optimizer=\"adam\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRmdoaQPFt4v"
      },
      "source": [
        "weight_dir = \"weight_tripletloss_model\"\n",
        "if not os.path.exists(weight_dir):\n",
        "    os.mkdir(weight_dir)\n",
        "    \n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=weight_dir+'/checkpoint-{epoch:02d}.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi_Bp6mNF755"
      },
      "source": [
        "Y_dummy = np.empty((anchor_images.shape[0],1))\n",
        "\n",
        "model.fit([anchor_images,same_images,diff_images],y=Y_dummy, batch_size=16, epochs=50, callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhzJiGPjHeyO"
      },
      "source": [
        "anchor_model = tf.keras.Model(inputs = anchor_input, outputs=encoded_anchor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR-TW0irHhAR"
      },
      "source": [
        "pred = anchor_model.predict(x_train)\n",
        "pred.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diKdjKPIIhzb"
      },
      "source": [
        "def img_encoding(imgpath,model):\n",
        "  f = cv2.imread(os.path.join(imgpath, f))\n",
        "  faces = face_cascade.detectMultiScale(f,1.3,5)\n",
        "  for x,y,w,h in faces:\n",
        "    img = f[y:y+h, x:x+w]\n",
        "    img = cv2.resize(img, (img_size,img_size))\n",
        "  pred=model.predict(img)\n",
        "  return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZm5CSxAJGJo"
      },
      "source": [
        "'''database={}\n",
        "database[\"Howard\"]=img_encoding(\"/content/Howard.jpg\",anchor_model)\n",
        "database[\"Leonard\"]=img_encoding(\"/content/Leonard.jpg\",anchor_model)\n",
        "database[\"Penny\"]=img_encoding(\"/content/Penny.jpg\",anchor_model)\n",
        "database[\"Sheldon\"]=img_encoding(\"/content/sheldon.jpg\",anchor_model)'''\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srTbTS-pZRCD"
      },
      "source": [
        "def encode_image(model ,img):\n",
        "    encode = model.predict(img.reshape((1,)+ img.shape))\n",
        "    encode=encode/255\n",
        "    print(encode)\n",
        "    return encode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuE4chF57Fff"
      },
      "source": [
        "def encode(model,dir):\n",
        "  test_image1 = cv2.imread(dir)\n",
        "  print(test_image1.shape)\n",
        "  test_image_gray1 = cv2.cvtColor(test_image1, cv2.COLOR_BGR2GRAY)\n",
        "  faces = face_cascade.detectMultiScale(test_image_gray1,1.3,5)\n",
        "  for x,y,w,h in faces:\n",
        "    img = test_image1[y:y+h, x:x+w]\n",
        "    img = cv2.resize(img, (60,60))\n",
        "  return encode_image(model,img)\n",
        "database={}\n",
        "\n",
        "database[\"jerryseinfield\"]=encode(anchor_model,\"/content/jerryseinfield.jpg\")\n",
        "database[\"Madonna\"]=encode(anchor_model,\"/content/Madonna.jpg\")\n",
        "database[\"benafflek\"]=encode(anchor_model,\"/content/benafflek.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV7l2vrW7-QE"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzKakNaxZDoV"
      },
      "source": [
        "name_dict = {}\n",
        "for i in set(df[\"name\"].values):\n",
        "    z = df[df[\"name\"] == i].image\n",
        "    img = np.array(list(z))/255\n",
        "    enc = np.zeros((1,128))\n",
        "    for j in range(len(z)):\n",
        "        enc += encode_image(anchor_model,img[j])\n",
        "\n",
        "    enc = enc/len(z)\n",
        "    name_dict[i] = enc\n",
        "#print(name_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frVdgvU_ZPuF"
      },
      "source": [
        "def who_is_it(image_path, database, model):\n",
        "    \n",
        "    encoding = encode_image(model,image_path)\n",
        "    print(encoding)\n",
        "    min_dist = 10000\n",
        "    for (name, db_enc) in database.items():\n",
        "        \n",
        "        dist = np.linalg.norm(encoding-db_enc)\n",
        "        if dist<min_dist:\n",
        "            min_dist = dist\n",
        "            identity = name\n",
        "    \n",
        "    if min_dist >0.1:\n",
        "        print(\"Not in the database.\")\n",
        "    else:\n",
        "        print (\"it's \" + str(identity) + \", the distance is \" + str(min_dist))\n",
        "        \n",
        "    return min_dist, identity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awIgUPcXaOe6"
      },
      "source": [
        "test_image1 = cv2.imread(\"/content/MV5BMTI4MzIxMTk0Nl5BMl5BanBnXkFtZTcwOTU5NjA0Mg@@._V1_UY1200_CR85,0,630,1200_AL_.jpg\")\n",
        "print(test_image1.shape)\n",
        "test_image_gray1 = cv2.cvtColor(test_image1, cv2.COLOR_BGR2GRAY)\n",
        "faces = face_cascade.detectMultiScale(test_image_gray1,1.3,5)\n",
        "for x,y,w,h in faces:\n",
        "  img = test_image1[y:y+h, x:x+w]\n",
        "  img = cv2.resize(img, (60,60))\n",
        "  plt.imshow(img)\n",
        "  print(who_is_it(img,database,anchor_model))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}